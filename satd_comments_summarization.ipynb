{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModelForSeq2SeqLM, T5Tokenizer, T5ForConditionalGeneration, RobertaTokenizer\n",
    "\n",
    "def get_device_map() -> str:\n",
    "    return 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "device = get_device_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>satd</th>\n",
       "      <th>comment_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>// if we are the dest and is a call action, cr...</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>// TR#18 1.2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>//Ignore manifest entries.  They're bound to c...</td>\n",
       "      <td>0</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>//NOTE: unlike all other Loaders, this one is ...</td>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>// no error as default</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>// the path to the plugin.xml descriptor file ...</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>// Test to see if correct suffix was used to c...</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>// TODO: figure out why bind variables aren't ...</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>// i'th argument</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>// Options</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>622 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          comment_text  satd  comment_length\n",
       "0    // if we are the dest and is a call action, cr...     0             112\n",
       "1                                         // TR#18 1.2     0              12\n",
       "2    //Ignore manifest entries.  They're bound to c...     0             167\n",
       "3    //NOTE: unlike all other Loaders, this one is ...     0              87\n",
       "4                               // no error as default     0              22\n",
       "..                                                 ...   ...             ...\n",
       "617  // the path to the plugin.xml descriptor file ...     0             100\n",
       "618  // Test to see if correct suffix was used to c...     0              65\n",
       "619  // TODO: figure out why bind variables aren't ...     1              53\n",
       "620                                   // i'th argument     0              16\n",
       "621                                         // Options     0              10\n",
       "\n",
       "[622 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "comment_df = pd.read_csv('sampled_data.csv')\n",
    "comment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Summarizer:\n",
    "    def __init__(self, model_checkpoint):\n",
    "        self.model_checkpoint = model_checkpoint\n",
    "        self.set_tokenizer(self.model_checkpoint)\n",
    "        self.set_model(self.model_checkpoint)\n",
    "        self.model_name = model_checkpoint.split(\"/\")[-1]\n",
    "        \n",
    "    def set_tokenizer(self, model_checkpoint):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "    \n",
    "    def set_model(self, model_checkpoint):\n",
    "        self.model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint, device_map=\"cuda:0\")\n",
    "    \n",
    "    def generate_summary(self, df, text_column='comment_text', prompt=None):\n",
    "        \n",
    "        summaries = []\n",
    "        if prompt == None:\n",
    "            prompt = \"Produce a summary of the following text:\"\n",
    "        else:\n",
    "            prompt = prompt\n",
    "        \n",
    "        for comment in df[text_column]:    \n",
    "            input_text = f\"{prompt} {comment}\"\n",
    "            inputs = self.tokenizer(input_text, return_tensors=\"pt\")\n",
    "            attention_mask = inputs[\"attention_mask\"].to(\"cuda\")\n",
    "            input_ids = inputs['input_ids'].to(\"cuda\")\n",
    "\n",
    "            outputs = self.model.generate(input_ids, \n",
    "                                          attention_mask=attention_mask, \n",
    "                                          do_sample=True,\n",
    "                                          num_return_sequences=1, \n",
    "                                          )\n",
    "            summary = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "            summaries.append(summary)\n",
    "\n",
    "        df['summary'] = summaries\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def export_summaries(self, df):\n",
    "        df.to_excel(f\"summarization_results/{self.model_name}_summaries.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlanSummarizer(Summarizer):    \n",
    "    def __init__(self, model_checkpoint):\n",
    "        super().__init__(model_checkpoint)\n",
    "        self.model_checkpoint = model_checkpoint\n",
    "        \n",
    "class BartLargeSummarizer(Summarizer):   \n",
    "    def __init__(self, model_checkpoint):\n",
    "        super().__init__(model_checkpoint)\n",
    "        self.model_checkpoint = model_checkpoint    \n",
    "        \n",
    "    def set_model(self, model_checkpoint):\n",
    "        self.model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n",
    "        self.model.load_state_dict(self.model.state_dict(), assign=True)\n",
    "        device = \"cuda:0\"\n",
    "        self.model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache() \n",
    "\n",
    "# summarizer = BartLargeSummarizer(\"facebook/bart-large-cnn\")\n",
    "# summarizer = FlanSummarizer(\"jordiclive/flan-t5-3b-summarizer\")\n",
    "summarizer = Summarizer(\"Falconsai/text_summarization\")\n",
    "\n",
    "summaries = summarizer.generate_summary(comment_df)\n",
    "\n",
    "summarizer.export_summaries(summaries)\n",
    "\n",
    "del summarizer\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
